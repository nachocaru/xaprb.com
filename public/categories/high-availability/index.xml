<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
      <title>High-Availability on Xaprb </title>
      <generator uri="https://hugo.spf13.com">Hugo</generator>
    <link>http://www.xaprb.com/categories/high-availability/index.xml/</link>
    
    
    
    <updated>Fri, 10 Jun 2011 00:00:00 UTC</updated>
    
    <item>
      <title>When can I have a big server in the cloud?</title>
      <link>http://www.xaprb.com/blog/2011/06/10/when-can-i-have-a-big-server-in-the-cloud/</link>
      <pubDate>Fri, 10 Jun 2011 00:00:00 UTC</pubDate>
      
      <guid>http://www.xaprb.com/blog/2011/06/10/when-can-i-have-a-big-server-in-the-cloud/</guid>
      <description>&lt;p&gt;I was at a conference recently talking with a Major Cloud Hosting Provider and mentioned that for database servers, I really want large instances, quite a bit larger than the largest I can get now. The lack of cloud servers with lots of memory, many &lt;em&gt;fast&lt;/em&gt; cores, and fast I/O and network performance leads to premature sharding, which is costly. A large number of applications can currently run on a single real server, but would require sharding to run in any of the popular cloud providers&amp;rsquo; environments. And many of those applications aren&amp;rsquo;t growing rapidly, so by the time they outgrow today&amp;rsquo;s hardware we can pretty much count on simply upgrading and staying on a single machine.&lt;/p&gt;

&lt;p&gt;The person I was talking to actually seemed to become angry at me, and basically called me an idiot. This person&amp;rsquo;s opinion is that no one should be running on anything larger than 4GB of memory, and anyone who doesn&amp;rsquo;t build their system to be sharded and massively horizontally scaled is clueless.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve received similar push-back from a lot of cloud hosting providers. When I work through the math with clients, a lot of them don&amp;rsquo;t like the ultimate price/performance ratio offered by cloud hosting. Hype doesn&amp;rsquo;t drive everyone&amp;rsquo;s business decisions, so a lot of people are wisely staying far away from cloud hosting for their applications, or even moving whole applications out of cloud hosting into real hardware to consolidate machines and save a lot of money. Some of them are using flash storage devices such as Fusion-io to further lower their TCO (this isn&amp;rsquo;t the right answer for every app, though).&lt;/p&gt;

&lt;p&gt;Why do cloud hosting providers work so hard to make everyone buy lots of anemic machines and shard their applications an order of magnitude more than is required? Why aren&amp;rsquo;t they jumping to offer really beefy instances? I think there are a couple of simple reasons.&lt;/p&gt;

&lt;p&gt;First, they want to colocate virtual machines and over-provision, just as airlines sell more tickets than there are seats in the plane. It&amp;rsquo;s a numbers game: sell more capacity than you really have, and bet on some of the instances not using all resources allocated to them. Win! Of course, this is only possible with lots of small instances; the law of large numbers doesn&amp;rsquo;t work without lots of instances, and large instances can&amp;rsquo;t be colocated. Cloud providers tend to dislike dedicated instances, which leads to the second reason. They don&amp;rsquo;t want to make strong claims about the availability of any particular machine. This is where the cloud paradigm of &amp;ldquo;you must build to recover from machines vanishing without warning&amp;rdquo; comes from. A dedicated beefy instance wouldn&amp;rsquo;t let the hosting provider push that responsibility onto the application.&lt;/p&gt;

&lt;p&gt;There are lots more reasons &amp;ndash; all of them combining into one big overall &amp;ldquo;cloud application architecture best practice&amp;rdquo; &amp;ndash; but I think those are two of the showstoppers.&lt;/p&gt;

&lt;p&gt;I really think this is a wrong paradigm. People talk about the cloud being the technology of the future, but in many ways it&amp;rsquo;s pretty stone-age compared to what smart system architects can achieve with high-quality hardware and networking at a much lower cost, with very strong guarantees of performance, consistency, and availability.&lt;/p&gt;

&lt;p&gt;Cloud computing is new enough that we don&amp;rsquo;t understand, in a collective sense, how to think about it. (I know that lots of individuals do, but as a whole, there isn&amp;rsquo;t much of a shared understanding.) The real value proposition that I want to see emerge from cloud computing is pretty much orthogonal to what everyone&amp;rsquo;s raving about these days. I want to see the DevOps engineering discipline build momentum around the idea that systems should be treated as services, with architectural components provisioned and controlled through APIs. That can be done completely independently of many of the characteristics of current cloud computing platforms (virtualization, ephemerality, horizontally scaled architectures&amp;hellip;)&lt;/p&gt;

&lt;p&gt;And like most people, I&amp;rsquo;ve got an ego and I don&amp;rsquo;t appreciate repeatedly being called a moron by cloud computing providers&amp;rsquo; sales people, who don&amp;rsquo;t know anything about running database servers. I can do math and understand price/performance, and I know the cost and difficulty of building a sharded application. I look forward to the day when I don&amp;rsquo;t have to just bite my tongue and walk on to the next booth. I look forward to cloud hosting providers advancing to the year 2005 or so. I&amp;rsquo;m sure it will happen as we figure this all out.&lt;/p&gt;

&lt;p&gt;Feel free to comment, but don&amp;rsquo;t expect me to approve your comment if you&amp;rsquo;re from a cloud provider and you&amp;rsquo;re plugging your platform :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>What&#39;s wrong with MMM?</title>
      <link>http://www.xaprb.com/blog/2011/05/04/whats-wrong-with-mmm/</link>
      <pubDate>Wed, 04 May 2011 00:00:00 UTC</pubDate>
      
      <guid>http://www.xaprb.com/blog/2011/05/04/whats-wrong-with-mmm/</guid>
      <description>&lt;p&gt;I am not a fan of the MMM tool for managing MySQL replication. This is a topic of vigorous debate among different people, and even within Percona not everyone feels the same way, which is why I&amp;rsquo;m posting it here instead of on an official Percona blog. There is room for legitimate differences of opinion, and my opinion is just my opinion. Nonetheless, I think it&amp;rsquo;s important to share, because a lot of people think of MMM as a high availability tool, and that&amp;rsquo;s not a decision to take lightly. At some point I just have to step off the treadmill and write a blog post to create awareness of what I see as a really bad situation that needs to be stopped.&lt;/p&gt;

&lt;p&gt;I like software that is well documented and formally tested. A lot of software is usable even if it isn&amp;rsquo;t created by perfectionists. But there are two major things in the MySQL world for which I think we can all agree we need strong guarantees of correctness. One is backups. The other is High Availability (HA) tools. And this leads me to my position on MMM.&lt;/p&gt;

&lt;p&gt;MMM is 1) fundamentally broken and unsuitable for use as a HA tool, and 2) absolutely cannot be fixed. I&amp;rsquo;ll take that in two parts.&lt;/p&gt;

&lt;p&gt;First, it&amp;rsquo;s broken and untrustworthy. I could go into the technical details of why MMM is broken at the architectural and implementation level. I could talk about the way that it uses a distributed set of agents, which do not have a reliable communications channel, all maintain their own state which is not communicated or agreed upon across nodes, and don&amp;rsquo;t even share configuration. I could talk about the fact that MMM itself can&amp;rsquo;t be made HA or redundant &amp;ndash; you can only have a single instance of it.&lt;/p&gt;

&lt;p&gt;I could talk about lots of things, but you can argue with every one of those assertions. You can&amp;rsquo;t argue with the list of failures I&amp;rsquo;ve personally seen. It fails over with no reason when nothing is wrong &amp;ndash; and botches it up, causing the entire replication cluster to get out of sync and break. It tries to fail over when something actually is wrong with the cluster, but it does things out of order and with no synchronization amongst the agents, leading to chaos. It can&amp;rsquo;t handle anything unexpected, such as the ordinary kinds of network, disk, etc failures you&amp;rsquo;d expect in systems that have something wrong (which is exactly when an HA tool is supposed to function). It doesn&amp;rsquo;t protect itself against the human doing something wrong, such as mixing up the agent configuration on different hosts. There are many bizarre ways MMM can fail, but these are all theoretical &amp;ndash; until you witness them. I&amp;rsquo;ve witnessed them, and new customer cases on MMM failures are filed on a regular basis. Here&amp;rsquo;s one:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;In the recent past, we have had a couple of bad experiences with mmm-monitor tool which broke replication and brought our website down for a few hours.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And another:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;We have recently started testing MMM for MySQL and when using it under write load we have been experiencing &amp;lsquo;Duplicate entry&amp;rsquo; (1062) errors.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In short, MMM causes more downtime than it prevents. It&amp;rsquo;s a Low-Availability tool, not a High-Availability tool. It only takes one really good serious system-wide mess to take you down for a couple of days, working 24&amp;#215;7 trying to scrape your data off the walls and put it back into the server. MMM brings new meaning to the term &amp;ldquo;cluster-f__k&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;Now, why isn&amp;rsquo;t it possible to fix it? One simple reason: MMM is completely untested and untestable. Change one line of code in Agent.pm&amp;rsquo;s master control flow and tell me that you&amp;rsquo;re confident that you know what it has just done to the whole system? You can&amp;rsquo;t do it. If you don&amp;rsquo;t have tests, you can&amp;rsquo;t change the code with confidence, period. And as I said before, HA and backup tools are where we need a zero-tolerance policy. &amp;ldquo;I think this fixed the bug&amp;rdquo; or &amp;ldquo;I think it&amp;rsquo;s safe to change this code&amp;rdquo; are not acceptable. I have seen a lot of bug fixes that cause new and interesting bugs. I appreciate the variety &amp;ndash; life is boring if all we&amp;rsquo;re doing is seeing the same old bugs &amp;ndash; but this isn&amp;rsquo;t what we need in an HA tool.&lt;/p&gt;

&lt;p&gt;In order to fix MMM, it has to be completely rewritten from scratch. Among other things, decisions and actions need to be completely separated. Then the decisions can be verified with a test suite, and the actions can be verified independently. But if you do that, you don&amp;rsquo;t have MMM anymore, you have a new tool. Therefore MMM can&amp;rsquo;t be fixed, it can only be thrown out and reimplemented.&lt;/p&gt;

&lt;p&gt;Note that I&amp;rsquo;m not claiming that MMM was developed by bad programmers or that it is bad quality. I am only claiming that a) it demonstrably doesn&amp;rsquo;t work correctly, and b) it can&amp;rsquo;t be fixed without a rigorous test suite, which can&amp;rsquo;t be added to it without a complete reimplementation.&lt;/p&gt;

&lt;p&gt;I will go further and claim that the architecture of MMM is fundamentally unreliable, and it isn&amp;rsquo;t a good idea to reimplement it (it&amp;rsquo;s already been done once!). This we could argue for a long time, but I know of so many better architectures that I wouldn&amp;rsquo;t entertain the notion of building a new tool with the same architecture.&lt;/p&gt;

&lt;p&gt;I have seen a number of people reach the same conclusions and then implement new systems in the same general vein as MMM, with a limited set of functionality to avoid some of the problems. For instance, Flipper is a single tool with no agents, so that&amp;rsquo;s an improvement. Unfortunately, these tools all suffer from the same problem: they aren&amp;rsquo;t formally tested. I simply can&amp;rsquo;t accept that in an HA tool.&lt;/p&gt;

&lt;p&gt;If I&amp;rsquo;m such a perfectionist, why haven&amp;rsquo;t I built a tool that solves this problem? I have a limited amount of time, and at some point, I don&amp;rsquo;t do things for free. I&amp;rsquo;ve had multiple conversations that go like this: &amp;ldquo;My last replication downtime incident cost me $75k. I can&amp;rsquo;t let that happen again. What will it cost to build a correct solution? No way &amp;ndash; I can&amp;rsquo;t pay $20k for a high availability tool that really works.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;There is active development on something related that I can&amp;rsquo;t talk much about now. But if you want, you can come to &lt;a href=&#34;http://www.percona.com/live/&#34;&gt;Percona Live&lt;/a&gt; and be among the first to find out.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Why high-availability is hard with databases</title>
      <link>http://www.xaprb.com/blog/2010/04/26/why-high-availability-is-hard-with-databases/</link>
      <pubDate>Mon, 26 Apr 2010 00:00:00 UTC</pubDate>
      
      <guid>http://www.xaprb.com/blog/2010/04/26/why-high-availability-is-hard-with-databases/</guid>
      <description>&lt;p&gt;A lot of systems are relatively easy to make HA (highly available). You just slap them into a well-known HA framework such as Linux-HA and you&amp;rsquo;re done. But databases are different, especially replicated databases, &lt;em&gt;especially&lt;/em&gt; replicated MySQL.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.xaprb.com/media/2010/04/matchbox_car-300x200.jpg&#34; alt=&#34;Matchbox Car&#34; title=&#34;Matchbox Car&#34; width=&#34;300&#34; height=&#34;200&#34; class=&#34;alignnone size-medium wp-image-1779&#34; style=&#34;float:right&#34; /&gt;The reason has to do with some properties that hold for many systems, but not for most databases. Most systems that you want to make HA are relatively lightweight and interchangeable, with little to zero statefulness, easy to start, easy to stop, don&amp;rsquo;t care a lot about storage (or at least don&amp;rsquo;t write a lot of data; that&amp;rsquo;s usually delegated to the database), and there&amp;rsquo;s little or no harm done if you ruthlessly behead them. The classic example is a web server or even most application servers. Most of the time these things are all about CPU power and network bandwidth. If I were to compare them to a car, I&amp;rsquo;d say they are like matchbox cars: there are many of them, and they are cheap and easy to replace.&lt;/p&gt;

&lt;p&gt;&lt;img style=&#34;float:right&#34; src=&#34;http://www.xaprb.com/media/2010/04/mining-truck-300x242.jpg&#34; alt=&#34;Mining Truck&#34; title=&#34;Mining Truck&#34; width=&#34;300&#34; height=&#34;242&#34; class=&#34;alignnone size-medium wp-image-1783&#34; /&gt;Databases are different. With or without replication, you&amp;rsquo;re looking at a system that is complex, stateful, heavyweight, and cares a lot about storage. It runs on bigger hardware with fast disks and a lot of memory. It&amp;rsquo;s usually disk-bound, and it does a lot of writes. It&amp;rsquo;s hard to start &amp;ndash; it takes a long time to warm up and really get ready to serve production workloads (many minutes, hours, or even days). It tends to run with a lot of data in memory in a dirty state, so shutdown is slow, because a clean shutdown requires flushing a bunch of data to disk. If you yank its power plug or kill-dash-nine it, it&amp;rsquo;ll have to perform recovery on startup, which slows the startup process even more. If I were to compare a database server to a car, I wouldn&amp;rsquo;t even use a car as the analogy: I&amp;rsquo;d use one of those big-ass mining trucks. If your mining truck breaks down, you don&amp;rsquo;t just toss it in the trash and pull another off the shelf.&lt;/p&gt;

&lt;p&gt;The problem with a lot of HA solutions is that they want to deal with inconsistencies or irregularities by killing the resource and replacing it in another location. This works fine with web servers, but not with database servers. Doing that will cause serious pain and downtime, defeating the point of HA. And when you add replication into the mix, it gets even worse. A system that wants to manage replication needs to deal with very complex conditions. A lot of replication failures are delicate matters that require skilled human intervention to solve. The HA solution must insulate the application from the misbehaving resource, but leave it running so the human can handle things.&lt;/p&gt;

&lt;p&gt;This is not the way most applications are made HA. It&amp;rsquo;s different with databases, and it&amp;rsquo;s much harder.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MySQL disaster recovery by promoting a slave</title>
      <link>http://www.xaprb.com/blog/2009/01/20/mysql-disaster-recovery-by-promoting-a-slave/</link>
      <pubDate>Tue, 20 Jan 2009 00:00:00 UTC</pubDate>
      
      <guid>http://www.xaprb.com/blog/2009/01/20/mysql-disaster-recovery-by-promoting-a-slave/</guid>
      <description>&lt;p&gt;I was just talking to someone who backs up their MySQL servers once a day with mysqldump, and I said in a catastrophe, you&amp;rsquo;re going to have to reload from a backup; that&amp;rsquo;s some amount of downtime, plus up to a day of lost data.&lt;/p&gt;

&lt;p&gt;And they said &amp;ldquo;We can just promote a slave, we&amp;rsquo;ve done it before. It works fine.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;Granted, in some/many cases, this is fine. There are all sorts of caveats &amp;ndash; for example, you either know that your &lt;a href=&#34;http://www.maatkit.org/doc/mk-table-checksum.html&#34;&gt;slave has the same data as the master&lt;/a&gt; or you don&amp;rsquo;t care. But it&amp;rsquo;s fine for some things.&lt;/p&gt;

&lt;p&gt;So then I said &amp;ldquo;what about DROP TABLE?&amp;rdquo;&lt;/p&gt;

&lt;p&gt;And there was a pause. I assume they were realizing that the chance of accidental or malicious destruction of data is much higher than the chance of multiple servers dying at once. This is why slave != backup.&lt;/p&gt;

&lt;p&gt;How about you?&lt;/p&gt;

&lt;p&gt;Granted, you can use a &lt;a href=&#34;http://www.maatkit.org/doc/mk-slave-delay.html&#34;&gt;delayed slave&lt;/a&gt; to protect against this particular scenario. But you still need &amp;ldquo;real&amp;rdquo; backups, and you still have to think about the worst case &amp;ndash; restoring that backup.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>